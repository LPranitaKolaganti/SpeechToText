{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TimeDistributed, Activation, Bidirectional, ConvLSTM2D, Attention, Dense, Flatten, MaxPool3D, MaxPool2D,BatchNormalization, Conv3D, GRU\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.backend import ctc_batch_cost, ctc_decode, ctc_label_dense_to_sparse\n",
    "\n",
    "import Levenshtein as Lev\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Decide\n",
    "1. Batch Norm vs Layer Norm or No Norm for attention model\n",
    "2. Shuffle or No\n",
    "\n",
    "To Do \n",
    "1. Check ss, sr\n",
    "2. check if shapes match\n",
    "3. append 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./LibriSpeech100/train/train_all/\"\n",
    "dev_path = \"./LibriSpeech100/dev/dev_all/\"\n",
    "test_path = \"./LibriSpeech100/test/test_all/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, path, to_fit = True):\n",
    "        self.path = path\n",
    "        self.list_X, self.list_Y = self.getLists()\n",
    "        self.to_fit = to_fit\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.list_X)\n",
    "    \n",
    "    def __getitem__(self, index):      \n",
    "        dict_X = self.get_dict_X(index)   \n",
    "        \n",
    "        if self.to_fit:\n",
    "            dict_Y = self.get_dict_Y(index)\n",
    "            X, Y = self.generate_XY(dict_X, dict_Y)\n",
    "            return X, Y\n",
    "        \n",
    "        X = self.generate_X(dict_X)\n",
    "        return X\n",
    "    \n",
    "    def getLists(self):\n",
    "        list_X = []\n",
    "        list_Y = []\n",
    "        for item in sorted(os.listdir(self.path)):\n",
    "            ext = item.split(\".\")[-1]\n",
    "            if ext == 'pkl':\n",
    "                list_X.append(item)\n",
    "            elif ext == 'txt':\n",
    "                list_Y.append(item)\n",
    "        return list_X, list_Y\n",
    "    \n",
    "    def get_dict_X(self, index):\n",
    "        file_name = self.path + self.list_X[index]\n",
    "        with open(file_name, 'rb') as pickle_file:\n",
    "            dict_X = pickle.load(pickle_file)\n",
    "        return dict_X\n",
    "    \n",
    "    def get_dict_Y(self, index):\n",
    "        file = open(train_path+filename)\n",
    "        dict_Y = {}\n",
    "        for line in file:\n",
    "            data = line.split()\n",
    "            key = data[0]\n",
    "            value = ' '.join(data[1:])\n",
    "            dict_Y[key] = value\n",
    "        return dict_Y\n",
    "    \n",
    "    def generate_XY(self, dict_X, dict_Y):\n",
    "        X = []\n",
    "        Y = []\n",
    "        for key in dict_X:\n",
    "            X.append(dict_X[key])\n",
    "            Y.append(dict_Y[key])\n",
    "        return X, Y\n",
    "    \n",
    "    def generate_X(self, dict_X):\n",
    "        X = [value.T for key, value in dict_X.items()]\n",
    "        X = tf.keras.preprocessing.sequence.pad_sequences(X, padding = 'post')\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer(s1, s2):\n",
    "\n",
    "    s1 =s1.lower()\n",
    "    s2 =s2.lower()\n",
    "    b = set(s1.lower().split() + s2.lower().split())\n",
    "    \n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "\n",
    "\n",
    "    w1 = [chr(word2char[w]) for w in s1.split()]\n",
    "    w2 = [chr(word2char[w]) for w in s2.split()]\n",
    "    return Lev.distance(''.join(w1), ''.join(w2))/float(len(s2.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataGenerator(train_path)\n",
    "val_data = DataGenerator(dev_path)\n",
    "test_data = DataGenerator(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(Model):\n",
    "    def __init__(self, op_dim = 28):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.rnn = GRU(output_dim, return_sequences= False)\n",
    "        self.y_pred = Activation('softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.rnn(inputs)\n",
    "        x = self.y_pred(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASRModel(Model):\n",
    "    def __init__(self):\n",
    "        super(ASRModel, self).__init__()\n",
    "        self.base_model = BaseModel()\n",
    "        self.activation = Activation('softmax')\n",
    "\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_data, labels, input_length, label_length = inputs\n",
    "        x = self.base_model(input_data)\n",
    "        x = self.activation()          \n",
    "        x = K.ctc_batch_cost(labels, x, input_length, label_length)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ASRModel(inputs = [input_data, labels, input_length, label_length])\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=tf.keras.optimizers.Adam(), metrics=[wer])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
